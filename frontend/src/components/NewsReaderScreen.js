import React, { useEffect, useState, useRef } from 'react';
import { 
  View, 
  Text, 
  ActivityIndicator, 
  TouchableOpacity, 
  StyleSheet, 
  Dimensions,
  ScrollView,
  Alert
} from 'react-native';
import { Ionicons } from '@expo/vector-icons';
import axios from 'axios';
import * as Speech from 'expo-speech';
import { Audio } from 'expo-av';
import { API_URL } from '../config/api';
import Header from './Header';

const { width, height } = Dimensions.get('window');

// Custom TTS function using backend API instead of expo-speech
const CustomSpeech = {
  speak: async (text, options = {}) => {
    try {
      if (!text || text.trim() === '') return;

      const { language = 'vi-VN', speed = 1.0, token } = options;
      
      console.log('TTS Request:', { text: text.substring(0, 50) + '...', language, speed });

      const response = await fetch(`${API_URL}/tts`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${token}`,
        },
        body: JSON.stringify({
          text,
          language,
          speed,
        }),
      });

      if (!response.ok) {
        throw new Error(`TTS API failed: ${response.status}`);
      }

      // Get response as array buffer
      const arrayBuffer = await response.arrayBuffer();
      
      // Convert to base64 for React Native
      const base64Audio = btoa(
        new Uint8Array(arrayBuffer).reduce((data, byte) => data + String.fromCharCode(byte), '')
      );
      
      const audioUri = `data:audio/mpeg;base64,${base64Audio}`;
      
      // Create and play audio using Expo Audio
      const { sound } = await Audio.Sound.createAsync(
        { uri: audioUri },
        { shouldPlay: true, volume: 1.0 }
      );

      console.log('TTS Audio playing successfully');
      
      return new Promise((resolve, reject) => {
        // Set completion callback
        sound.setOnPlaybackStatusUpdate((status) => {
          if (status.didJustFinish) {
            sound.unloadAsync();
            resolve();
          }
          if (status.error) {
            sound.unloadAsync();
            reject(new Error('Audio playback error'));
          }
        });
      });

    } catch (error) {
      console.error('Custom TTS Error:', error);
      // Fallback: show alert if TTS fails
      Alert.alert('TTS Error', error.message);
      throw error;
    }
  },

  stop: () => {
    // Stop current TTS if needed
    console.log('TTS Stop requested');
  }
};

const NewsReaderScreen = ({ theme, token, t, onLogout, onSettingsPress }) => {
  const [articles, setArticles] = useState([]);
  const [selected, setSelected] = useState(null);
  const [isRecording, setIsRecording] = useState(false);
  const [isPlaying, setIsPlaying] = useState(false);
  const [isLoadingNews, setIsLoadingNews] = useState(false);
  const [selectedArticleIndex, setSelectedArticleIndex] = useState(null);
  const [isContinuousListening, setIsContinuousListening] = useState(false);
  const [audioLevel, setAudioLevel] = useState(0);
  const sound = useRef(new Audio.Sound());
  const recording = useRef(null);
  const continuousRecording = useRef(null);
  const isDark = theme === 'dark';

  // L·∫•y ng√†y th√°ng hi·ªán t·∫°i
  const getCurrentDate = () => {
    const now = new Date();
    const day = now.getDate();
    const month = now.getMonth() + 1;
    const year = now.getFullYear();
    
    return t.language === 'vi' 
      ? `ng√†y ${day} th√°ng ${month} nƒÉm ${year}`
      : `${month}/${day}/${year}`;
  };

  // L·∫•y danh s√°ch b√†i vi·∫øt t·ª´ backend
  const fetchNews = async () => {
    try {
      setIsLoadingNews(true);
      const res = await axios.get(`${API_URL}/news`); 
      setArticles(res.data);
      
      console.log('News data received:', res.data); // Debug log

      if (res.data.length > 0) {
        // Welcome message v·ªõi ng√†y th√°ng
        const currentDate = getCurrentDate();
        const welcomeText = t.language === 'vi' 
          ? `T√¥i l√† tr·ª£ l√Ω ƒë·ªçc tin t·ª©c, h√¥m nay ${currentDate} c√≥ c√°c tin t·ª©c n√≥ng sau:`
          : `I am your news reading assistant, today ${currentDate} we have the following hot news:`;
        
        CustomSpeech.speak(welcomeText, { 
          language: t.language === 'vi' ? 'vi-VN' : 'en-US', 
          token 
        });
        
        // ƒê·ªçc danh s√°ch 5 tin m·ªõi nh·∫•t
        setTimeout(() => {
          const maxArticles = Math.min(5, res.data.length);
          let currentIndex = 0;
          
          const readNextArticle = () => {
            if (currentIndex < maxArticles) {
              const articleText = t.language === 'vi' 
                ? `Tin s·ªë ${currentIndex + 1}: ${res.data[currentIndex].title}`
                : `News ${currentIndex + 1}: ${res.data[currentIndex].title}`;
              
              CustomSpeech.speak(articleText, { 
                language: t.language === 'vi' ? 'vi-VN' : 'en-US', 
                token 
              });
              currentIndex++;
              
              // ƒê·ªçc tin ti·∫øp theo sau 4 gi√¢y
              setTimeout(readNextArticle, 4000);
            } else {
              // Sau khi ƒë·ªçc xong, b·∫≠t continuous listening
              setTimeout(() => {
                const instructionText = t.language === 'vi' 
                  ? 'B·∫°n c√≥ th·ªÉ n√≥i tin s·ªë m·∫•y ƒë·ªÉ nghe, ho·∫∑c n√≥i d·ª´ng, ti·∫øp t·ª•c ƒë·ªÉ ƒëi·ªÅu khi·ªÉn.'
                  : 'You can say news number to listen, or say stop, continue to control.';
                CustomSpeech.speak(instructionText, { 
                  language: t.language === 'vi' ? 'vi-VN' : 'en-US', 
                  token 
                });
                
                setTimeout(() => {
                  startContinuousListening();
                }, 2000);
              }, 2000);
            }
          };
          
          readNextArticle();
        }, 3000); // Delay 3s sau welcome message
      }
    } catch (err) {
      console.error('Fetch news failed', err);
      const errorText = t.language === 'vi' 
        ? 'Kh√¥ng th·ªÉ t·∫£i tin t·ª©c. Vui l√≤ng th·ª≠ l·∫°i.'
        : 'Failed to load news. Please try again.';
      CustomSpeech.speak(errorText, { 
        language: t.language === 'vi' ? 'vi-VN' : 'en-US', 
        token 
      });
    } finally {
      setIsLoadingNews(false);
    }
  };

  // Ch·ªçn b√†i b√°o b·∫±ng index
  const selectArticle = (index) => {
    if (index >= 0 && index < articles.length) {
      // Stop continuous listening when selecting article
      stopContinuousListening();
      
      setSelectedArticleIndex(index);
      setSelected(articles[index]);
      
      const selectedText = t.language === 'vi' 
        ? `ƒê√£ ch·ªçn tin s·ªë ${index + 1}: ${articles[index].title}`
        : `Selected news ${index + 1}: ${articles[index].title}`;
      CustomSpeech.speak(selectedText, { 
        language: t.language === 'vi' ? 'vi-VN' : 'en-US', 
        token 
      });
      
      // Auto-play audio sau 2 gi√¢y
      setTimeout(() => {
        playNewsAudio(index);
      }, 2000);
    }
  };

  // L·∫•y audio URL v√† ph√°t
  const playNewsAudio = async (articleIndex) => {
    try {
      const article = articles[articleIndex];
      setSelected(article);
      setSelectedArticleIndex(articleIndex);
      
      console.log('Playing article:', article);
      
      const loadingText = t.language === 'vi' 
        ? `ƒêang t·∫£i audio tin s·ªë ${articleIndex + 1}`
        : `Loading audio for news ${articleIndex + 1}`;
      CustomSpeech.speak(loadingText, { 
        language: t.language === 'vi' ? 'vi-VN' : 'en-US', 
        token 
      });
      
      const res = await axios.get(`${API_URL}/news/audio`, {
        params: { url: article.url },
      });

      console.log('Audio response:', res.data);

      const audioUrl = res.data.audioUrl;
      if (!audioUrl) {
        const noAudioText = t.language === 'vi' 
          ? "Tin n√†y kh√¥ng c√≥ file √¢m thanh, s·∫Ω ƒë·ªçc n·ªôi dung b·∫±ng gi·ªçng n√≥i"
          : "This news has no audio file, will read content with text-to-speech";
        CustomSpeech.speak(noAudioText, { 
          language: t.language === 'vi' ? 'vi-VN' : 'en-US', 
          token 
        });
        
        // Fallback: ƒë·ªçc title b·∫±ng TTS
        setTimeout(() => {
          CustomSpeech.speak(article.title, { 
            language: t.language === 'vi' ? 'vi-VN' : 'en-US', 
            token 
          });
          // Start continuous listening after TTS
          setTimeout(() => {
            startContinuousListening();
          }, 5000);
        }, 2000);
        return;
      }

      await sound.current.unloadAsync();
      await sound.current.loadAsync({ uri: audioUrl });
      await sound.current.playAsync();
      setIsPlaying(true);
      
      // Start continuous listening khi b·∫Øt ƒë·∫ßu ph√°t audio
      setTimeout(() => {
        startContinuousListening();
      }, 3000);
      
      // Listen for audio completion
      sound.current.setOnPlaybackStatusUpdate((status) => {
        if (status.didJustFinish) {
          setIsPlaying(false);
          stopContinuousListening();
          
          const finishedText = t.language === 'vi' 
            ? 'ƒê√£ ph√°t xong tin n√†y. B·∫°n c√≥ th·ªÉ ch·ªçn tin kh√°c.'
            : 'Finished playing this news. You can select another news.';
          CustomSpeech.speak(finishedText, { 
            language: t.language === 'vi' ? 'vi-VN' : 'en-US', 
            token 
          });
          
          // Restart continuous listening after completion
          setTimeout(() => {
            startContinuousListening();
          }, 2000);
        }
      });
      
    } catch (err) {
      console.error('Error playing audio', err);
      const errorText = t.language === 'vi' 
        ? `Kh√¥ng th·ªÉ ph√°t audio tin n√†y. S·∫Ω ƒë·ªçc b·∫±ng gi·ªçng n√≥i.`
        : `Cannot play audio for this news. Will read with text-to-speech.`;
      CustomSpeech.speak(errorText, { 
        language: t.language === 'vi' ? 'vi-VN' : 'en-US', 
        token 
      });
      
      // Fallback: ƒë·ªçc title b·∫±ng TTS khi c√≥ l·ªói
      setTimeout(() => {
        CustomSpeech.speak(articles[articleIndex].title, { 
          language: t.language === 'vi' ? 'vi-VN' : 'en-US', 
          token 
        });
        setTimeout(() => {
          startContinuousListening();
        }, 5000);
      }, 1000);
    }
  };

  // D·ª´ng v√† ti·∫øp t·ª•c
  const pauseAudio = async () => {
    await sound.current.pauseAsync();
    setIsPlaying(false);
    // Keep continuous listening active when paused
  };
  
  const resumeAudio = async () => {
    await sound.current.playAsync();
    setIsPlaying(true);
    // Ensure continuous listening is active
    if (!isContinuousListening) {
      setTimeout(() => {
        startContinuousListening();
      }, 1000);
    }
  };

  // Simple similarity calculation
  const calculateSimilarity = (str1, str2) => {
    const words1 = str1.split(' ');
    const words2 = str2.split(' ');
    const commonWords = words1.filter(word => words2.some(w => w.includes(word) || word.includes(w)));
    return commonWords.length / Math.max(words1.length, words2.length);
  };

  // Continuous listening functions
  const startContinuousListening = async () => {
    if (isContinuousListening) return;
    
    try {
      const permission = await Audio.requestPermissionsAsync();
      if (permission.status !== 'granted') return;

      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });

      const { recording } = await Audio.Recording.createAsync({
        ...Audio.RECORDING_OPTIONS_PRESET_HIGH_QUALITY,
        android: {
          extension: '.m4a',
          outputFormat: Audio.RECORDING_OPTION_ANDROID_OUTPUT_FORMAT_MPEG_4,
          audioEncoder: Audio.RECORDING_OPTION_ANDROID_AUDIO_ENCODER_AAC,
          sampleRate: 44100,
          numberOfChannels: 1,
          bitRate: 128000,
        },
        ios: {
          extension: '.m4a',
          outputFormat: Audio.RECORDING_OPTION_IOS_OUTPUT_FORMAT_MPEG4AAC,
          audioQuality: Audio.RECORDING_OPTION_IOS_AUDIO_QUALITY_MEDIUM,
          sampleRate: 44100,
          numberOfChannels: 1,
          bitRate: 128000,
          linearPCMBitDepth: 16,
          linearPCMIsBigEndian: false,
          linearPCMIsFloat: false,
        },
      });

      continuousRecording.current = recording;
      setIsContinuousListening(true);

      // Monitor audio levels
      recording.setOnRecordingStatusUpdate((status) => {
        if (status.metering) {
          setAudioLevel(status.metering);
        }
      });

      // Auto-process after 3 seconds of recording
      setTimeout(() => {
        if (isContinuousListening) {
          processContinuousRecording();
        }
      }, 3000);

    } catch (err) {
      console.error('Failed to start continuous listening:', err);
    }
  };

  const processContinuousRecording = async () => {
    if (!continuousRecording.current) return;

    try {
      await continuousRecording.current.stopAndUnloadAsync();
      const uri = continuousRecording.current.getURI();
      continuousRecording.current = null;
      setIsContinuousListening(false);

      // Check if there was significant audio input
      if (audioLevel > -40) { // Threshold for detecting speech
        await sendAudioForProcessing(uri, true); // true = continuous mode
      } else {
        console.log('No significant audio detected, not sending to API');
        // Restart continuous listening after a short delay
        setTimeout(() => {
          if (!isRecording) { // Only restart if not manually recording
            startContinuousListening();
          }
        }, 1000);
      }
    } catch (error) {
      console.error('Error processing continuous recording:', error);
      setIsContinuousListening(false);
    }
  };

  const stopContinuousListening = () => {
    if (continuousRecording.current) {
      continuousRecording.current.stopAndUnloadAsync();
      continuousRecording.current = null;
    }
    setIsContinuousListening(false);
  };

  // Enhanced voice command processing
  const processVoiceCommand = (text, isContinuous = false) => {
    const lowerText = text.toLowerCase().trim();
    console.log('Processing voice command:', lowerText, 'Continuous:', isContinuous);
    
    // Control commands
    const controlCommands = {
      stop: ['d·ª´ng', 'stop', 't·∫°m d·ª´ng', 'pause'],
      continue: ['ti·∫øp t·ª•c', 'continue', 'ph√°t', 'play'],
      next: ['tin ti·∫øp theo', 'next', 'b√†i ti·∫øp theo'],
      previous: ['tin tr∆∞·ªõc', 'previous', 'b√†i tr∆∞·ªõc'],
      repeat: ['l·∫∑p l·∫°i', 'repeat', 'ƒë·ªçc l·∫°i']
    };

    // Check for control commands first
    for (const [action, keywords] of Object.entries(controlCommands)) {
      if (keywords.some(keyword => lowerText.includes(keyword))) {
        executeControlCommand(action);
        
        // Restart continuous listening after control command
        if (isContinuous) {
          setTimeout(() => startContinuousListening(), 1000);
        }
        return;
      }
    }

    // Check for number patterns (tin s·ªë X, b√†i s·ªë X)
    const numberPatterns = [
      /tin\s*s·ªë\s*(\d+)/,
      /b√†i\s*s·ªë\s*(\d+)/,
      /news\s*(\d+)/,
      /article\s*(\d+)/,
      /s·ªë\s*(\d+)/,
      /^(\d+)$/
    ];

    for (const pattern of numberPatterns) {
      const match = lowerText.match(pattern);
      if (match) {
        const articleNumber = parseInt(match[1]);
        if (articleNumber >= 1 && articleNumber <= articles.length) {
          console.log('Found article by number:', articleNumber);
          selectArticle(articleNumber - 1);
          
          // Don't restart continuous listening when selecting article
          return;
        }
      }
    }

    // If continuous mode and no command found, restart listening
    if (isContinuous) {
      setTimeout(() => startContinuousListening(), 1000);
    } else {
      // Handle article selection by keywords (for manual commands)
      handleArticleSelection(lowerText);
    }
  };

  const executeControlCommand = async (action) => {
    switch (action) {
      case 'stop':
        if (isPlaying) {
          pauseAudio();
          const stopText = t.language === 'vi' ? 'ƒê√£ t·∫°m d·ª´ng' : 'Paused';
          CustomSpeech.speak(stopText, { 
            language: t.language === 'vi' ? 'vi-VN' : 'en-US', 
            token 
          });
        }
        break;
      case 'continue':
        if (!isPlaying && selected) {
          resumeAudio();
          const continueText = t.language === 'vi' ? 'Ti·∫øp t·ª•c ph√°t' : 'Continuing playback';
          CustomSpeech.speak(continueText, { 
            language: t.language === 'vi' ? 'vi-VN' : 'en-US', 
            token 
          });
        }
        break;
      case 'next':
        if (selectedArticleIndex !== null && selectedArticleIndex < articles.length - 1) {
          selectArticle(selectedArticleIndex + 1);
        }
        break;
      case 'previous':
        if (selectedArticleIndex !== null && selectedArticleIndex > 0) {
          selectArticle(selectedArticleIndex - 1);
        }
        break;
      case 'repeat':
        if (selectedArticleIndex !== null) {
          selectArticle(selectedArticleIndex);
        }
        break;
    }
  };

  const handleArticleSelection = (lowerText) => {
    // Enhanced keyword matching (existing code)
    const vietnameseKeywords = {
      'm·ªπ': ['m·ªπ', 'america', 'usa'],
      'vi·ªát nam': ['vi·ªát nam', 'vietnam'],
      'trump': ['trump', '√¥ng trump'],
      'iran': ['iran'],
      'th√°i lan': ['th√°i lan', 'thailand'],
      't√†u': ['t√†u', 'tau'],
      'c·∫£nh s√°t': ['c·∫£nh s√°t', 'canh sat'],
      'b·∫Øt': ['b·∫Øt', 'bat'],
      'ƒë∆∞·ªùng s·∫Øt': ['ƒë∆∞·ªùng s·∫Øt', 'duong sat', 'ƒë∆∞·ªùng ray'],
      'xe √¥m': ['xe √¥m', 'xe om', 'grab'],
      'hun sen': ['hun sen']
    };

    let bestMatch = null;
    let highestScore = 0;

    articles.forEach((article, index) => {
      const articleTitle = article.title.toLowerCase();
      let score = 0;

      score += calculateSimilarity(lowerText, articleTitle) * 10;

      Object.keys(vietnameseKeywords).forEach(keyword => {
        if (articleTitle.includes(keyword)) {
          vietnameseKeywords[keyword].forEach(variant => {
            if (lowerText.includes(variant)) {
              score += 5;
            }
          });
        }
      });

      const voiceWords = lowerText.split(' ');
      const titleWords = articleTitle.split(' ');
      
      voiceWords.forEach(voiceWord => {
        if (voiceWord.length > 2) {
          titleWords.forEach(titleWord => {
            if (titleWord.includes(voiceWord) || voiceWord.includes(titleWord)) {
              score += 2;
            }
          });
        }
      });

      if (score > highestScore) {
        highestScore = score;
        bestMatch = { article, index };
      }
    });

    if (bestMatch && highestScore > 3) {
      selectArticle(bestMatch.index);
    } else {
      const noMatchText = t.language === 'vi' 
        ? 'Kh√¥ng t√¨m th·∫•y b√†i b√°o ph√π h·ª£p. Th·ª≠ n√≥i tin s·ªë m·∫•y.'
        : 'No matching article found. Try saying news number.';
      CustomSpeech.speak(noMatchText, { 
        language: t.language === 'vi' ? 'vi-VN' : 'en-US', 
        token 
      });
    }
  };

  // Voice recording handlers (manual)
  const handleRecordPress = async () => {
    if (isRecording) {
      await stopRecording();
    } else {
      await startRecording();
    }
  };

  const startRecording = async () => {
    try {
      // Stop continuous listening khi recording th·ªß c√¥ng
      stopContinuousListening();
      
      const permission = await Audio.requestPermissionsAsync();
      if (permission.status !== 'granted') {
        const permissionText = t.language === 'vi' 
          ? 'C·∫ßn quy·ªÅn truy c·∫≠p microphone ƒë·ªÉ ghi √¢m'
          : 'Microphone permission required for recording';
        Alert.alert('Permission Required', permissionText);
        return;
      }

      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });

      const { recording } = await Audio.Recording.createAsync(
        Audio.RECORDING_OPTIONS_PRESET_HIGH_QUALITY
      );
      recording.current = recording;
      setIsRecording(true);

      const recordingText = t.language === 'vi' 
        ? 'ƒêang ghi √¢m... N√≥i tin s·ªë m·∫•y ho·∫∑c l·ªánh ƒëi·ªÅu khi·ªÉn'
        : 'Recording... Say news number or control command';
      CustomSpeech.speak(recordingText, { 
        language: t.language === 'vi' ? 'vi-VN' : 'en-US', 
        token 
      });
    } catch (err) {
      console.error('Failed to start recording:', err);
      const errorText = t.language === 'vi' 
        ? 'Kh√¥ng th·ªÉ b·∫Øt ƒë·∫ßu ghi √¢m'
        : 'Failed to start recording';
      Alert.alert('Error', errorText);
    }
  };

  const stopRecording = async () => {
    try {
      setIsRecording(false);
      if (recording.current) {
        await recording.current.stopAndUnloadAsync();
        const uri = recording.current.getURI();
        recording.current = null;
        
        // Send audio to speech-to-text API (manual mode)
        await sendAudioForProcessing(uri, false);
      }
    } catch (error) {
      console.error('Failed to stop recording:', error);
      const errorText = t.language === 'vi' 
        ? 'Kh√¥ng th·ªÉ d·ª´ng ghi √¢m'
        : 'Failed to stop recording';
      Alert.alert('Error', errorText);
    }
  };

  // Send audio to speech-to-text API
  const sendAudioForProcessing = async (audioUri, isContinuous = false) => {
    try {
      const formData = new FormData();
      formData.append('audio', {
        uri: audioUri,
        type: 'audio/m4a',
        name: 'voice_command.m4a',
      });
      formData.append('language', t.language === 'vi' ? 'vi-VN' : 'en-US');

      const response = await fetch(`${API_URL}/speech`, {
        method: 'POST',
        body: formData,
        headers: {
          'Authorization': `Bearer ${token}`,
          'Content-Type': 'multipart/form-data',
        },
      });

      if (!response.ok) {
        throw new Error('Speech-to-text request failed');
      }

      const data = await response.json();
      console.log('Speech recognition result:', data);

      if (data.text) {
        // Process the voice command
        processVoiceCommand(data.text, isContinuous);
      } else {
        const noSpeechText = t.language === 'vi' 
          ? 'Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c gi·ªçng n√≥i. Vui l√≤ng th·ª≠ l·∫°i.'
          : 'No speech detected. Please try again.';
        CustomSpeech.speak(noSpeechText, { 
          language: t.language === 'vi' ? 'vi-VN' : 'en-US', 
          token 
        });
      }
    } catch (error) {
      console.error('Error processing speech:', error);
      const errorText = t.language === 'vi' 
        ? 'L·ªói x·ª≠ l√Ω gi·ªçng n√≥i. Vui l√≤ng th·ª≠ l·∫°i.'
        : 'Speech processing error. Please try again.';
      CustomSpeech.speak(errorText, { 
        language: t.language === 'vi' ? 'vi-VN' : 'en-US', 
        token 
      });
    }
  };

  // Cleanup on component unmount
  useEffect(() => {
    return () => {
      stopContinuousListening();
      if (recording.current) {
        recording.current.stopAndUnloadAsync();
      }
      if (sound.current) {
        sound.current.unloadAsync();
      }
    };
  }, []);

  useEffect(() => {
    fetchNews();
  }, []);

  return (
    <View style={[
      styles.container,
      { backgroundColor: isDark ? '#343541' : '#ffffff' }
    ]}>
      <Header
        theme={theme}
        title={t.newsReader || 'News Reader'}
        onMenuPress={() => {}} // No sidebar in news reader
        onLogout={onLogout}
        onSettingsPress={onSettingsPress}
      />

      <ScrollView style={styles.content} showsVerticalScrollIndicator={false}>
        <View style={[
          styles.newsContainer,
          { backgroundColor: isDark ? '#202123' : '#f5f5f5' }
        ]}>
          <Text style={[
            styles.title,
            { color: isDark ? '#fff' : '#000' }
          ]}>
            {t.newsReader || 'Tin t·ª©c m·ªõi nh·∫•t'}
          </Text>
          
          {isLoadingNews ? (
            <View style={styles.loadingContainer}>
              <ActivityIndicator size="large" color={isDark ? '#fff' : '#007AFF'} />
              <Text style={[
                styles.loadingText,
                { color: isDark ? '#ccc' : '#666' }
              ]}>
                {t.language === 'vi' ? 'ƒêang t·∫£i tin t·ª©c...' : 'Loading news...'}
              </Text>
            </View>
          ) : (
            <>
              {selected && (
                <View style={[
                  styles.selectedContainer,
                  { backgroundColor: isDark ? '#2C2C2E' : '#E3F2FD' }
                ]}>
                  <Text style={[
                    styles.selectedLabel,
                    { color: isDark ? '#4CAF50' : '#1976D2' }
                  ]}>
                    {t.language === 'vi' ? 'ƒêang ph√°t:' : 'Now playing:'}
                  </Text>
                  <Text style={[
                    styles.selectedTitle,
                    { color: isDark ? '#fff' : '#000' }
                  ]}>
                    {selected.title}
                  </Text>
                  <View style={styles.audioControls}>
                    <TouchableOpacity
                      style={[styles.controlButton, { backgroundColor: isDark ? '#4CAF50' : '#2196F3' }]}
                      onPress={isPlaying ? pauseAudio : resumeAudio}
                    >
                      <Ionicons
                        name={isPlaying ? "pause" : "play"}
                        size={20}
                        color="#fff"
                      />
                      <Text style={styles.controlButtonText}>
                        {isPlaying ? (t.language === 'vi' ? 'D·ª´ng' : 'Pause') : (t.language === 'vi' ? 'Ph√°t' : 'Play')}
                      </Text>
                    </TouchableOpacity>
                  </View>
                </View>
              )}

              {/* Article List */}
              <View style={styles.articleList}>
                <Text style={[
                  styles.sectionTitle,
                  { color: isDark ? '#fff' : '#000' }
                ]}>
                  {t.language === 'vi' 
                    ? `Danh s√°ch b√†i b√°o (${articles.length} b√†i):` 
                    : `Article List (${articles.length} articles):`
                  }
                </Text>
                <Text style={[
                  styles.instructionText,
                  { color: isDark ? '#888' : '#666' }
                ]}>
                  {t.language === 'vi' 
                    ? 'Nh·∫•n v√†o b√†i b√°o ho·∫∑c n√≥i "B√†i s·ªë X" ƒë·ªÉ ch·ªçn'
                    : 'Tap on article or say "Article X" to select'
                  }
                </Text>
                {articles.map((article, index) => (
                  <TouchableOpacity
                    key={index}
                    style={[
                      styles.articleItem,
                      selectedArticleIndex === index && styles.selectedArticleItem,
                      { 
                        backgroundColor: selectedArticleIndex === index 
                          ? (isDark ? '#2C2C2E' : '#E3F2FD')
                          : (isDark ? '#1E1E1E' : '#fff'),
                        borderColor: isDark ? '#333' : '#E0E0E0'
                      }
                    ]}
                    onPress={() => selectArticle(index)}
                  >
                    <View style={styles.articleRow}>
                      <View style={[
                        styles.articleNumber,
                        { backgroundColor: selectedArticleIndex === index ? '#4CAF50' : (isDark ? '#4CAF50' : '#2196F3') }
                      ]}>
                        <Text style={[
                          styles.articleNumberText,
                          { color: '#fff' }
                        ]}>
                          {index + 1}
                        </Text>
                      </View>
                      <View style={styles.articleContent}>
                        <Text style={[
                          styles.articleTitle,
                          { color: isDark ? '#fff' : '#000' }
                        ]} numberOfLines={3}>
                          {article.title}
                        </Text>
                      </View>
                      {selectedArticleIndex === index && (
                        <Ionicons
                          name="volume-high"
                          size={24}
                          color={isDark ? '#4CAF50' : '#2196F3'}
                        />
                      )}
                    </View>
                  </TouchableOpacity>
                ))}
              </View>
            </>
          )}
        </View>
      </ScrollView>

      {/* Large Voice Control Button */}
      <View style={styles.voiceControlContainer}>
        {isContinuousListening && (
          <View style={[
            styles.listeningIndicator,
            { backgroundColor: isDark ? '#4CAF50' : '#2196F3' }
          ]}>
            <Text style={styles.listeningText}>
              {t.language === 'vi' ? 'üé§ ƒêang l·∫Øng nghe...' : 'üé§ Listening...'}
            </Text>
          </View>
        )}
        
        <TouchableOpacity
          style={[
            styles.recordButton,
            isRecording && styles.recordingButton,
            { backgroundColor: isRecording ? '#ff4444' : '#007AFF' }
          ]}
          onPress={handleRecordPress}
          disabled={isLoadingNews}
        >
          <Ionicons
            name={isRecording ? "stop" : "mic"}
            size={60}
            color="#fff"
          />
        </TouchableOpacity>
        
        <Text style={[
          styles.recordButtonLabel,
          { color: isDark ? '#fff' : '#000' }
        ]}>
          {isRecording 
            ? (t.recording || 'ƒêang ghi √¢m...') 
            : (t.tapToRecord || 'Nh·∫•n ƒë·ªÉ ghi √¢m th·ªß c√¥ng')
          }
        </Text>
        
        <Text style={[
          styles.recordButtonHint,
          { color: isDark ? '#888' : '#666' }
        ]}>
          {t.language === 'vi' 
            ? 'N√≥i: "Tin s·ªë X", "D·ª´ng", "Ti·∫øp t·ª•c", "Tin ti·∫øp theo"'
            : 'Say: "News X", "Stop", "Continue", "Next news"'
          }
        </Text>
        
        {audioLevel > -40 && isContinuousListening && (
          <View style={styles.audioLevelIndicator}>
            <Text style={[
              styles.audioLevelText,
              { color: isDark ? '#4CAF50' : '#2196F3' }
            ]}>
              üîä Audio Level: {Math.round(audioLevel + 60)}%
            </Text>
          </View>
        )}
      </View>
    </View>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
  },
  content: {
    flex: 1,
    padding: 16,
  },
  newsContainer: {
    flex: 1,
    padding: 20,
    borderRadius: 12,
    marginBottom: 20,
  },
  title: {
    fontSize: 24,
    fontWeight: 'bold',
    marginBottom: 16,
    textAlign: 'center',
  },
  selectedContainer: {
    padding: 16,
    borderWidth: 2,
    borderColor: '#4CAF50',
    borderRadius: 8,
    marginBottom: 16,
  },
  selectedLabel: {
    fontSize: 16,
    fontWeight: 'bold',
    marginBottom: 8,
  },
  selectedTitle: {
    fontSize: 18,
    fontWeight: 'bold',
  },
  audioControls: {
    flexDirection: 'row',
    justifyContent: 'flex-start',
    alignItems: 'center',
    marginTop: 12,
  },
  controlButton: {
    flexDirection: 'row',
    alignItems: 'center',
    paddingVertical: 8,
    paddingHorizontal: 16,
    borderRadius: 20,
  },
  controlButtonText: {
    fontSize: 14,
    fontWeight: '600',
    color: '#fff',
    marginLeft: 8,
  },
  articleList: {
    marginBottom: 20,
  },
  sectionTitle: {
    fontSize: 18,
    fontWeight: 'bold',
    marginBottom: 16,
  },
  articleItem: {
    padding: 16,
    borderWidth: 1,
    borderColor: '#E0E0E0',
    borderRadius: 8,
    marginBottom: 8,
  },
  articleRow: {
    flexDirection: 'row',
    alignItems: 'center',
  },
  articleNumber: {
    width: 30,
    height: 30,
    borderRadius: 15,
    justifyContent: 'center',
    alignItems: 'center',
    marginRight: 16,
  },
  articleNumberText: {
    fontSize: 14,
    fontWeight: 'bold',
    color: '#fff',
  },
  articleContent: {
    flex: 1,
  },
  articleTitle: {
    fontSize: 16,
    fontWeight: 'bold',
    marginBottom: 8,
  },
  selectedArticleItem: {
    borderWidth: 2,
    borderColor: '#4CAF50',
  },
  voiceControlContainer: {
    alignItems: 'center',
    paddingBottom: 40,
    paddingTop: 20,
  },
  recordButton: {
    width: 120,
    height: 120,
    borderRadius: 60,
    justifyContent: 'center',
    alignItems: 'center',
    shadowOffset: {
      width: 0,
      height: 4,
    },
    shadowOpacity: 0.3,
    shadowRadius: 4.65,
    elevation: 8,
  },
  recordingButton: {
    transform: [{ scale: 1.1 }],
  },
  recordButtonLabel: {
    fontSize: 16,
    fontWeight: '600',
    marginTop: 16,
    textAlign: 'center',
  },
  recordButtonHint: {
    fontSize: 14,
    color: '#666',
    marginTop: 8,
  },
  loadingContainer: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
  },
  loadingText: {
    marginTop: 16,
  },
  instructionText: {
    fontSize: 14,
    marginBottom: 16,
    fontStyle: 'italic',
  },
  listeningIndicator: {
    padding: 8,
    borderRadius: 8,
    marginBottom: 16,
  },
  listeningText: {
    fontSize: 16,
    fontWeight: 'bold',
  },
  audioLevelIndicator: {
    padding: 8,
    borderRadius: 8,
    marginTop: 16,
  },
  audioLevelText: {
    fontSize: 14,
    fontWeight: 'bold',
  },
});

export default NewsReaderScreen;
